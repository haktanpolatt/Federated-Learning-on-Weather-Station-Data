{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc4bc1a",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d977c6f",
   "metadata": {},
   "source": [
    "1. Installing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a06bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d274b78",
   "metadata": {},
   "source": [
    "2. Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f574d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mixed_wind_speed(value):\n",
    "    if isinstance(value, (int, float)): # Eğer zaten sayısal ise doğrudan döndür\n",
    "        return float(value)\n",
    "    if isinstance(value, str):\n",
    "        # Önce \"X.AyAdı\" formatını dene\n",
    "        match_month = re.match(r\"(\\d+(?:\\.\\d+)?)\\.(?:Oca|Şub|Mar|Nis|May|Haz|Tem|Ağu|Eyl|Eki|Kas|Ara)\", value, re.IGNORECASE)\n",
    "        if match_month:\n",
    "            try:\n",
    "                return float(match_month.group(1))\n",
    "            except ValueError:\n",
    "                return np.nan # Sayısal kısım parse edilemezse NaN\n",
    "\n",
    "        # Sonra doğrudan sayısal olup olmadığını dene (virgül ve nokta ondalık ayırıcılarını destekle)\n",
    "        try:\n",
    "            # Önce virgülü noktaya çevir (eğer varsa), sonra float'a çevirmeyi dene\n",
    "            return float(value.replace(',', '.'))\n",
    "        except ValueError:\n",
    "            return np.nan # Hiçbir format uyuşmuyorsa NaN\n",
    "    return np.nan # Diğer tipler için (list, dict vb.) NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd02a8",
   "metadata": {},
   "source": [
    "3. Data Loading and Initial Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11b3e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri başarıyla yüklendi.\n",
      "CSV'den yüklenen ve temizlenen sütun adları: ['WMO Station ID', 'Date', 'Sea level pressure', '3-hour pressure variation', 'Barometric trend type', '10-min mean wind direction', '10-min mean wind speed', 'Temperature', 'Dew point', 'Humidity', 'Horizontal visibility', 'Present weather', 'Past weather 1', 'Past weather 2', 'Total cloud cover', 'Lower-level cloud cover', 'Lower-level cloud base height', 'Lower-level cloud type', 'Middle-level cloud type', 'Upper-level cloud type', 'Station pressure', 'Barometric level', 'Geopotential', '24-hour pressure variation', '12-hour minimum temperature', '24-hour minimum temperature', '12-hour maximum temperature', '24-hour maximum temperature', '12-hour minimum ground temperature', 'Measurement method Wet-bulb temperature', 'Wet-bulb temperature', 'Gust over last 10 minutes', 'Gusts over a period', 'Gust measurement period', 'Ground condition', 'Total height of snow, ice, other layer on the ground', 'Height of fresh snow', 'Measurement period of fresh snow', 'Precipitation in the last hour', 'Precipitation in the last 3 hours', 'Precipitation in the last 6 hours', 'Precipitation in the last 12 hours', 'Precipitation in the last 24 hours', 'Special phenomenon 1', 'Special phenomenon 2', 'Special phenomenon 3', 'Special phenomenon 4', 'Cloud cover 1', 'Cloud type 1', 'Base height 1', 'Cloud cover 2', 'Cloud type 2', 'Base height 2', 'Cloud cover 3', 'Cloud type 3', 'Base height 3', 'Cloud cover 4', 'Cloud type 4', 'Base height 4', 'Coordinates', 'Name', 'Barometric trend type.1', 'Past weather 1.1', 'Present weather.1', 'Temperature (C)', '12-hour minimum temperature (C)', '24-hour minimum temperature (C)', '12-hour maximum temperature (C)', '24-hour maximum temperature (C)', '12-hour minimum ground temperature (in C)', 'Latitude', 'Longitude', 'Altitude', 'municipalities (name)', 'municipalities (code)', 'EPCI (name)', 'EPCI (code)', 'department (name)', 'department (code)', 'region (name)', 'region (code)', 'month_of_the_yearx']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hakta\\AppData\\Local\\Temp\\ipykernel_19064\\3541557434.py:2: DtypeWarning: Columns (62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_main = pd.read_csv('Data/dataset_synop.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_main = pd.read_csv('Data/dataset_synop.csv', sep=';')\n",
    "    # Sütun adlarındaki başındaki/sonundaki boşlukları temizle\n",
    "    df_main.columns = df_main.columns.str.strip()\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: 'dataset_synop.csv' dosyası bulunamadı. Lütfen dosya yolunu kontrol edin.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Veri başarıyla yüklendi.\")\n",
    "print(\"CSV'den yüklenen ve temizlenen sütun adları:\", df_main.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846af58d",
   "metadata": {},
   "source": [
    "4. Feature Transformations and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474b9817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_dir_sin ve wind_dir_cos sütunları eklendi.\n",
      "wind_pressure_interaction sütunu eklendi.\n"
     ]
    }
   ],
   "source": [
    "df_processed = df_main.copy()\n",
    "\n",
    "# Açısal veriyi dönüştür (0-360 derece → sin/cos)\n",
    "if '10-min mean wind direction' in df_processed.columns:\n",
    "    radians = np.radians(df_processed['10-min mean wind direction'])\n",
    "    df_processed['wind_dir_sin'] = np.sin(radians)\n",
    "    df_processed['wind_dir_cos'] = np.cos(radians)\n",
    "    print(\"wind_dir_sin ve wind_dir_cos sütunları eklendi.\")\n",
    "\n",
    "if 'wind_dir_sin' in df_processed.columns and 'Sea level pressure' in df_processed.columns:\n",
    "    df_processed['wind_pressure_interaction'] = df_processed['wind_dir_sin'] * df_processed['Sea level pressure']\n",
    "    print(\"wind_pressure_interaction sütunu eklendi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eede0a8",
   "metadata": {},
   "source": [
    "5. Clearing Columns and Numeric Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c323bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_to_predict = ['10-min mean wind speed', 'Humidity', 'Temperature', '10-min mean wind direction']\n",
    "other_potential_features = [\n",
    "    'Sea level pressure', '3-hour pressure variation', 'Dew point',\n",
    "    'Horizontal visibility', 'Total cloud cover', 'Station pressure',\n",
    "    '24-hour pressure variation', 'Precipitation in the last 24 hours'\n",
    "]\n",
    "engineered_features = ['wind_dir_sin', 'wind_dir_cos', 'wind_pressure_interaction']\n",
    "all_relevant_columns = sorted(list(set(targets_to_predict + other_potential_features + engineered_features)))\n",
    "month_string_columns = ['10-min mean wind speed'] # Bu artık yanıltıcı olabilir, belki mixed_format_wind_columns gibi bir isim?\n",
    "\n",
    "# Sütunları işle (tip dönüşümü)\n",
    "for col in df_processed.columns: # Veya sadece all_relevant_columns içinde dönebilirsiniz\n",
    "    if col == '10-min mean wind speed': # Sadece bu özel sütun için yeni fonksiyonu kullan\n",
    "        df_processed[col] = df_processed[col].apply(parse_mixed_wind_speed)\n",
    "    elif col in all_relevant_columns and col not in month_string_columns: # Diğer sayısal sütunlar\n",
    "        if col not in df_processed.columns: # Bu kontrol aslında döngü df_processed.columns üzerinde olduğu için gereksiz\n",
    "            continue\n",
    "        df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "    # month_string_columns içindeki diğer sütunlar (eğer varsa) eski parse_month_string_value ile işlenebilir\n",
    "    # veya onlar için de ayrı bir mantık gerekebilir. Şu an sadece rüzgar hızı için bu özel durumu ele alıyoruz.\n",
    "\n",
    "for col in all_relevant_columns:\n",
    "    if col in df_processed.columns:\n",
    "        if col not in month_string_columns:\n",
    "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "    else:\n",
    "        # Eğer month_string_columns içinde değilse ve df_processed'da yoksa, burada da uyarı verilebilir.\n",
    "        if col not in month_string_columns: # month_string_columns için uyarı yukarıda verildi\n",
    "             print(f\"Uyarı: Ana DataFrame'de '{col}' sütunu bulunamadı. CSV başlıklarını kontrol edin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a709ff0",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f823ba1",
   "metadata": {},
   "source": [
    "Modeling with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f34658ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SENARYO 1 BAŞLIYOR (Belirtilen hedefler için Random Forest) ---\n",
      "Toplam 2 istasyon bulundu.\n",
      "\n",
      "--- İstasyon ID: 7761 ---\n",
      "  --- Hedef Değişken: 10-min mean wind speed ---\n",
      "      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\n",
      "    Random Forest: MAE=1.1960, MSE=2.9237, RMSE=1.7099, R2=-0.1051, MAPE=49.25%\n",
      "    Model boyutu: 3.95 MB\n",
      "  --- Hedef Değişken: Humidity ---\n",
      "    Random Forest: MAE=0.7008, MSE=2.3734, RMSE=1.5406, R2=0.9877, MAPE=1.05%\n",
      "    Model boyutu: 1.65 MB\n",
      "  --- Hedef Değişken: Temperature ---\n",
      "    Random Forest: MAE=0.0706, MSE=0.0546, RMSE=0.2337, R2=0.9988, MAPE=0.02%\n",
      "    Model boyutu: 1.88 MB\n",
      "  --- Hedef Değişken: 10-min mean wind direction ---\n",
      "      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\n",
      "    Random Forest: MAE=0.0000, MSE=0.0000, RMSE=0.0000, R2=1.0000, MAPE=0.00%\n",
      "    Model boyutu: 0.01 MB\n",
      "\n",
      "--- İstasyon ID: 7790 ---\n",
      "  --- Hedef Değişken: 10-min mean wind speed ---\n",
      "      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\n",
      "    Random Forest: MAE=1.2804, MSE=3.5044, RMSE=1.8720, R2=-0.0606, MAPE=59.30%\n",
      "    Model boyutu: 3.92 MB\n",
      "  --- Hedef Değişken: Humidity ---\n",
      "    Random Forest: MAE=1.3643, MSE=6.6267, RMSE=2.5742, R2=0.9745, MAPE=2.08%\n",
      "    Model boyutu: 2.31 MB\n",
      "  --- Hedef Değişken: Temperature ---\n",
      "    Random Forest: MAE=0.0890, MSE=0.0989, RMSE=0.3145, R2=0.9979, MAPE=0.03%\n",
      "    Model boyutu: 2.15 MB\n",
      "  --- Hedef Değişken: 10-min mean wind direction ---\n",
      "      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\n",
      "    Random Forest: MAE=0.0000, MSE=0.0000, RMSE=0.0000, R2=1.0000, MAPE=0.00%\n",
      "    Model boyutu: 0.01 MB\n",
      "\n",
      "Senaryo 1 tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "station_ids = df_processed['WMO Station ID'].unique()\n",
    "print(f\"\\n--- SENARYO 1 BAŞLIYOR (Belirtilen hedefler için Random Forest) ---\")\n",
    "print(f\"Toplam {len(station_ids)} istasyon bulundu.\")\n",
    "\n",
    "for station_id in station_ids:\n",
    "    print(f\"\\n--- İstasyon ID: {station_id} ---\")\n",
    "    \n",
    "    df_station_raw = df_processed[df_processed['WMO Station ID'] == station_id].copy()\n",
    "    \n",
    "    station_cols_available = [col for col in all_relevant_columns if col in df_station_raw.columns]\n",
    "    if not station_cols_available:\n",
    "        print(f\"  Uyarı: {station_id} istasyonu için {all_relevant_columns} listesinden hiçbir ilgili sütun bulunamadı. Atlanıyor.\")\n",
    "        continue\n",
    "        \n",
    "    df_station_data = df_station_raw[station_cols_available].copy()\n",
    "    df_station_data.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    if df_station_data.empty or len(df_station_data.columns) < 2:\n",
    "        print(f\"  Uyarı: {station_id} istasyonu için (NaN sütunlar çıkarıldıktan sonra) modelleme yapılacak yeterli ({len(df_station_data.columns)}) sütun bulunamadı. Atlanıyor.\")\n",
    "        continue\n",
    "        \n",
    "    for target_col in targets_to_predict:\n",
    "        if target_col not in df_station_data.columns:\n",
    "            print(f\"  Uyarı: Hedef değişken '{target_col}', {station_id} istasyon verisinde (df_station_data içinde) bulunmuyor. Atlanıyor.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  --- Hedef Değişken: {target_col} ---\")\n",
    "        \n",
    "        y_station_full = df_station_data[target_col].copy()\n",
    "        X_station_full = df_station_data.drop(columns=[target_col], errors='ignore')\n",
    "\n",
    "        if X_station_full.empty:\n",
    "            print(f\"    Uyarı: {target_col} için özellik kalmadı. Atlanıyor.\")\n",
    "            continue\n",
    "            \n",
    "        valid_target_indices = y_station_full.dropna().index\n",
    "        y_station = y_station_full.loc[valid_target_indices]\n",
    "        X_station = X_station_full.loc[valid_target_indices]\n",
    "        \n",
    "        if X_station.empty or y_station.empty or len(X_station) < 5:\n",
    "            print(f\"    Uyarı: {target_col} için hedefte NaN olmayan yeterli veri ({len(X_station)} satır) kalmadı. Atlanıyor.\")\n",
    "            continue\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_station, y_station, test_size=0.2, random_state=42)\n",
    "        \n",
    "        if X_train.empty or X_test.empty:\n",
    "            print(f\"    Uyarı: {target_col} için train/test split sonrası boş küme(ler) oluştu. Atlanıyor.\")\n",
    "            continue\n",
    "\n",
    "        feature_names = X_train.columns.tolist()\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=feature_names)\n",
    "        X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=feature_names)\n",
    "\n",
    "        y_test_reset = y_test.reset_index(drop=True)\n",
    "        X_test_imputed_reset = X_test_imputed.reset_index(drop=True)\n",
    "\n",
    "        y_test_name_original = y_test_reset.name if y_test_reset.name is not None else target_col # Fallback to target_col\n",
    "        y_test_name_for_concat = y_test_name_original\n",
    "        # Ensure unique column name for y in concat\n",
    "        i = 0\n",
    "        while y_test_name_for_concat in X_test_imputed_reset.columns:\n",
    "            y_test_name_for_concat = f\"{y_test_name_original}_{i}\"\n",
    "            i += 1\n",
    "        if y_test_name_original != y_test_name_for_concat:\n",
    "             y_test_reset = y_test_reset.rename(y_test_name_for_concat)\n",
    "\n",
    "\n",
    "        temp_test_df = pd.concat([X_test_imputed_reset, y_test_reset], axis=1)\n",
    "        cleaned_test_df = temp_test_df.dropna()\n",
    "\n",
    "        if cleaned_test_df.empty:\n",
    "            print(f\"    Uyarı: {target_col} için test setinde NaN temizliği sonrası veri kalmadı. Atlanıyor.\")\n",
    "            continue\n",
    "            \n",
    "        X_test_final = cleaned_test_df.drop(columns=[y_test_name_for_concat]) # Use the name used in concat\n",
    "        y_test_final = cleaned_test_df[y_test_name_for_concat]\n",
    "        \n",
    "        if X_test_final.empty or y_test_final.empty or len(X_test_final) < 1 :\n",
    "            print(f\"    Uyarı: {target_col} için test seti temizlik sonrası yetersiz ({len(X_test_final)} örnek). Atlanıyor.\")\n",
    "            continue\n",
    "\n",
    "        model = DecisionTreeRegressor(random_state=42)\n",
    "        \n",
    "        try:\n",
    "            model.fit(X_train_imputed, y_train)\n",
    "            y_pred = model.predict(X_test_final)\n",
    "            \n",
    "            mae = mean_absolute_error(y_test_final, y_pred)\n",
    "            mse = mean_squared_error(y_test_final, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = np.nan\n",
    "            mape = np.nan \n",
    "            r2_note = \"\"\n",
    "\n",
    "            if len(y_test_final) >= 2:\n",
    "                r2 = r2_score(y_test_final, y_pred)\n",
    "            else:\n",
    "                r2_note = \" (R² tanımsız: <2 test örneği)\"\n",
    "            \n",
    "            # Calculate MAPE if possible\n",
    "            # Check for zeros in y_test_final to avoid division by zero or انفجار MAPE\n",
    "            if not np.isinf(y_pred).any() and not np.isnan(y_pred).any(): # Ensure y_pred is clean\n",
    "                if np.all(y_test_final != 0): # Ensure no zeros in actual values\n",
    "                    mape = mean_absolute_percentage_error(y_test_final, y_pred) * 100\n",
    "                else:\n",
    "                    # For rows where y_test_final is 0, MAPE is problematic.\n",
    "                    # We can calculate MAPE for non-zero rows or report as N/A.\n",
    "                    non_zero_mask = y_test_final != 0\n",
    "                    if np.any(non_zero_mask): # If there are some non-zero values\n",
    "                        mape = mean_absolute_percentage_error(y_test_final[non_zero_mask], y_pred[non_zero_mask]) * 100\n",
    "                        print(f\"      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\")\n",
    "                    else: # All y_test_final are zero\n",
    "                        print(f\"      Bilgi: MAPE hesaplanamıyor (tüm y_test_final değerleri sıfır).\")\n",
    "                        mape = np.nan # explicitly set to nan\n",
    "            else:\n",
    "                print(f\"      Bilgi: MAPE hesaplanamıyor (y_pred'de inf veya NaN değerler var).\")\n",
    "\n",
    "\n",
    "            # Prepare MAPE string for printing\n",
    "            mape_str_display = \"N/A\"\n",
    "            if not np.isnan(mape) and not np.isinf(mape):\n",
    "                mape_str_display = f\"{mape:.2f}%\"\n",
    "            \n",
    "            r2_display = f\"{r2:.4f}\" if not np.isnan(r2) else \"N/A\" \n",
    "            print(f\"    Random Forest: MAE={mae:.4f}, MSE={mse:.4f}, RMSE={rmse:.4f}, R2={r2_display}{r2_note}, MAPE={mape_str_display}\")\n",
    "\n",
    "            save_dir = f\"Sizes/DecisionTree/Scenario 1/{station_id}\"\n",
    "            os.makedirs(save_dir, exist_ok=True) \n",
    "\n",
    "            joblib.dump(model, f\"Sizes/DecisionTree/Scenario 1/{station_id}/{target_col}.pkl\")\n",
    "            model_size = os.path.getsize(f\"Sizes/DecisionTree/Scenario 1/{station_id}/{target_col}.pkl\") / (1024 * 1024)\n",
    "            print(f\"    Model boyutu: {model_size:.2f} MB\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Hata (Random Forest modeli, {target_col} hedefi için, İstasyon {station_id}): {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "print(\"\\nSenaryo 1 tamamlandı.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4458f26",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ba40c",
   "metadata": {},
   "source": [
    "Modeling with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "634570df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelleme için kullanılacak sütunlar: ['10-min mean wind direction', '10-min mean wind speed', '24-hour pressure variation', '3-hour pressure variation', 'Dew point', 'Horizontal visibility', 'Humidity', 'Precipitation in the last 24 hours', 'Sea level pressure', 'Station pressure', 'Temperature', 'Total cloud cover', 'wind_dir_cos', 'wind_dir_sin', 'wind_pressure_interaction']\n",
      "\n",
      "--- SENARYO 2 BAŞLIYOR (Belirtilen hedefler için Random Forest) ---\n",
      "\n",
      "--- Hedef Değişken: 10-min mean wind speed ---\n",
      "  Model Eğitiliyor: Decision Tree...\n",
      "      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\n",
      "    Decision Tree: MAE=1.3170, MSE=3.6520, RMSE=1.9110, R2=-0.1968, MAPE=58.49%\n",
      "    Model boyutu: 7.93 MB\n",
      "\n",
      "--- Hedef Değişken: Humidity ---\n",
      "  Model Eğitiliyor: Decision Tree...\n",
      "      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\n",
      "    Decision Tree: MAE=0.4488, MSE=1.8933, RMSE=1.3760, R2=0.9917, MAPE=0.64%\n",
      "    Model boyutu: 2.15 MB\n",
      "\n",
      "--- Hedef Değişken: Temperature ---\n",
      "  Model Eğitiliyor: Decision Tree...\n",
      "      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\n",
      "    Decision Tree: MAE=0.0418, MSE=0.0411, RMSE=0.2028, R2=0.9991, MAPE=0.01%\n",
      "    Model boyutu: 2.83 MB\n",
      "\n",
      "--- Hedef Değişken: 10-min mean wind direction ---\n",
      "  Model Eğitiliyor: Decision Tree...\n",
      "      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\n",
      "    Decision Tree: MAE=0.0000, MSE=0.0000, RMSE=0.0000, R2=1.0000, MAPE=0.00%\n",
      "    Model boyutu: 0.01 MB\n",
      "\n",
      "Senaryo 2 tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "# Modelleme için kullanılacak nihai sütunları belirle (var olan ve tamamen NaN olmayanlar)\n",
    "df_model_pool = df_processed[all_relevant_columns].copy()\n",
    "df_model_pool.dropna(axis=1, how='all', inplace=True)\n",
    "final_columns_for_modeling = df_model_pool.columns.tolist()\n",
    "\n",
    "if not final_columns_for_modeling or len(final_columns_for_modeling) < 2:\n",
    "    print(\"Hata: Modelleme için yeterli sütun kalmadı. Script sonlandırılıyor.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Modelleme için kullanılacak sütunlar: {final_columns_for_modeling}\")\n",
    "\n",
    "# --- Senaryo 2: Tüm veriyi birleştir ve belirtilen hedefler için model eğit ---\n",
    "print(f\"\\n--- SENARYO 2 BAŞLIYOR (Belirtilen hedefler için Random Forest) ---\")\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42)\n",
    "}\n",
    "# Diğer modeller (Linear Regression, Gradient Boosting, Neural Network, XGBoost) istenirse buraya eklenebilir.\n",
    "\n",
    "results_summary = {}\n",
    "\n",
    "for target_col in targets_to_predict:\n",
    "    if target_col not in final_columns_for_modeling:\n",
    "        print(f\"Uyarı: Hedef değişken '{target_col}' kullanılabilir sütunlar arasında değil. Atlanıyor.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- Hedef Değişken: {target_col} ---\")\n",
    "    results_summary[target_col] = {}\n",
    "\n",
    "    current_data_for_target = df_model_pool.copy() # Her hedef için temiz bir başlangıç\n",
    "\n",
    "    # X (özellikler) ve y (hedef) ayır\n",
    "    y_full = current_data_for_target[target_col].copy()\n",
    "    # Özellikler, hedefin kendisi hariç `final_columns_for_modeling` içindeki tüm sütunlar olmalı\n",
    "    feature_pool = [col for col in final_columns_for_modeling if col != target_col]\n",
    "    if not feature_pool:\n",
    "        print(f\"    Uyarı: {target_col} için özellik sütunu kalmadı. Atlanıyor.\")\n",
    "        continue\n",
    "    X_full = current_data_for_target[feature_pool].copy()\n",
    "    \n",
    "    # Hedef değişkende NaN olan satırları çıkar\n",
    "    valid_target_indices = y_full.dropna().index\n",
    "    y = y_full.loc[valid_target_indices]\n",
    "    X = X_full.loc[valid_target_indices]\n",
    "\n",
    "    if X.empty or y.empty or len(X) < 5: # Train/test split için yeterli satır kontrolü\n",
    "        print(f\"    Uyarı: {target_col} için hedefte NaN olmayan yeterli veri ({len(X)} satır) kalmadı. Atlanıyor.\")\n",
    "        continue\n",
    "    \n",
    "    # Veriyi eğitim ve test setlerine ayır\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if X_train.empty or X_test.empty:\n",
    "        print(f\"    Uyarı: {target_col} için train/test split sonrası boş küme(ler) oluştu. Atlanıyor.\")\n",
    "        continue\n",
    "        \n",
    "    # Eğitim setindeki (X_train) NaN değerleri medyan ile doldur\n",
    "    feature_names = X_train.columns.tolist()\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=feature_names)\n",
    "    \n",
    "    # Test setindeki (X_test) NaN değerleri eğitim setinden öğrenilen imputer ile doldur\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=feature_names)\n",
    "\n",
    "    # İsteğe göre: Test bölümündeki (X_test_imputed ve y_test) NaN içeren satırları dropla\n",
    "    y_test_reset = y_test.reset_index(drop=True)\n",
    "    X_test_imputed_reset = X_test_imputed.reset_index(drop=True)\n",
    "    \n",
    "    y_test_name = y_test_reset.name if y_test_reset.name else 'target_variable'\n",
    "    if y_test_name in X_test_imputed_reset.columns:\n",
    "        y_test_name = f\"{y_test_name}_y\"\n",
    "\n",
    "    temp_test_df = pd.concat([X_test_imputed_reset, y_test_reset.rename(y_test_name)], axis=1)\n",
    "    cleaned_test_df = temp_test_df.dropna()\n",
    "\n",
    "    if cleaned_test_df.empty:\n",
    "        print(f\"    Uyarı: {target_col} için test setinde NaN temizliği sonrası veri kalmadı. Atlanıyor.\")\n",
    "        continue\n",
    "            \n",
    "    X_test_final = cleaned_test_df.drop(columns=[y_test_name])\n",
    "    y_test_final = cleaned_test_df[y_test_name]\n",
    "\n",
    "    if X_test_final.empty or y_test_final.empty:\n",
    "        print(f\"    Uyarı: {target_col} için test seti (X veya y) temizlik sonrası boş kaldı. Atlanıyor.\")\n",
    "        continue\n",
    "    if len(X_test_final) < 1:\n",
    "         print(f\"    Uyarı: {target_col} için test seti temizlik sonrası yetersiz ({len(X_test_final)} örnek). Atlanıyor.\")\n",
    "         continue\n",
    "         \n",
    "    # Özellikleri ölçeklendir (Linear Regression, Neural Network gibi modeller için önemli olabilir)\n",
    "    # Random Forest için genellikle gerekmez ama tutarlılık için eklenebilir veya çıkarılabilir.\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "    # X_test_scaled = scaler.transform(X_test_final)\n",
    "    # Kullanılacak X setleri:\n",
    "    X_train_to_use = X_train_imputed # Ölçeklendirme yoksa\n",
    "    X_test_to_use = X_test_final   # Ölçeklendirme yoksa\n",
    "    # Eğer ölçeklendirme aktif edilirse:\n",
    "    # X_train_to_use = X_train_scaled\n",
    "    # X_test_to_use = X_test_scaled\n",
    "\n",
    "    for model_name, model_instance in models.items():\n",
    "        print(f\"  Model Eğitiliyor: {model_name}...\")\n",
    "        try:\n",
    "            current_model = model_instance # Modelin taze kopyası\n",
    "            current_model.fit(X_train_to_use, y_train) # y_train NaN'lardan arındırılmıştı\n",
    "            \n",
    "            if X_test_to_use.shape[0] > 0:\n",
    "                y_pred = current_model.predict(X_test_to_use)\n",
    "                \n",
    "                mae = mean_absolute_error(y_test_final, y_pred)\n",
    "                mse = mean_squared_error(y_test_final, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = np.nan\n",
    "                mape = np.nan\n",
    "                r2_note = \"\"\n",
    "\n",
    "                if len(y_test_final) >= 2:\n",
    "                    r2 = r2_score(y_test_final, y_pred)\n",
    "                else:\n",
    "                    r2_note = \" (R² tanımsız: <2 test örneği)\"\n",
    "                \n",
    "                non_zero_mask = y_test_final != 0\n",
    "                if np.any(non_zero_mask):\n",
    "                    mape = mean_absolute_percentage_error(y_test_final[non_zero_mask], y_pred[non_zero_mask]) * 100\n",
    "                    print(\"      Bilgi: MAPE, y_test_final'daki sıfır olmayan değerler için hesaplandı.\")\n",
    "                else:\n",
    "                    print(\"      Bilgi: MAPE hesaplanamıyor (tüm y_test_final değerleri sıfır).\")\n",
    "                    mape = np.nan\n",
    "\n",
    "                mape_str = f\"{mape:.2f}%\" if not np.isnan(mape) else \"N/A\"\n",
    "                print(f\"    {model_name}: MAE={mae:.4f}, MSE={mse:.4f}, RMSE={rmse:.4f}, R2={r2:.4f}{r2_note}, MAPE={mape_str}\")\n",
    "                results_summary[target_col][model_name] = {\n",
    "                    \"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2 if not np.isnan(r2) else None, \"MAPE\": mape if not np.isnan(mape) else None\n",
    "                }\n",
    "                if r2_note:\n",
    "                     results_summary[target_col][model_name][\"Not_R2\"] = r2_note.strip()\n",
    "            else:                \n",
    "                print(f\"    {model_name}: Test verisi kalmadığı için metrikler hesaplanamadı.\")\n",
    "                results_summary[target_col][model_name] = {\n",
    "                    \"MAE\": np.nan, \"MSE\": np.nan, \"RMSE\": np.nan, \"R2\": np.nan, \"MAPE\": np.nan,\n",
    "                    \"Not\": \"Yetersiz/Boş test verisi\"\n",
    "                }\n",
    "\n",
    "            save_dir = f\"Sizes/DecisionTree/Scenario 2\"\n",
    "            os.makedirs(save_dir, exist_ok=True) \n",
    "\n",
    "            joblib.dump(models, f\"Sizes/DecisionTree/Scenario 2/{target_col}.pkl\")\n",
    "            model_size = os.path.getsize(f\"Sizes/DecisionTree/Scenario 2/{target_col}.pkl\") / (1024 * 1024)\n",
    "            print(f\"    Model boyutu: {model_size:.2f} MB\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Hata ({model_name} modeli, {target_col} hedefi için): {e}\")\n",
    "            results_summary[target_col][model_name] = {\"MAE\": np.nan, \"MSE\": np.nan, \"RMSE\": np.nan, \"R2\": np.nan, \"MAPE\": np.nan, \"Hata\": str(e)}\n",
    "\n",
    "# Sonuçların özetini yazdır (isteğe bağlı)\n",
    "# ... (results_summary DataFrame'e dönüştürülüp yazdırılabilir) ...\n",
    "\n",
    "print(\"\\nSenaryo 2 tamamlandı.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
